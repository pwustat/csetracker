---
title: 'ASA SLDS Webinar: Towards Secure and Interpretable AI - Scalable Methods,
  Interactive Visualizations, and Practical Tools '
author: ''
date: '2021-05-25T10:00:00-07:00'
slug: asa-slds-webinar-towards-secure-and-interpretable-ai-scalable-methods-interactive-visualizations-and-practical-tools
categories:
  - Data Science
tags: []
type: webinar
url_register: ~
url_freeregister: https://www.eventbrite.com/e/may-slds-webinar-tickets-153659679237
url_slides: ~
url_video: https://www.youtube.com/watch?v=r1UM6IAqw5M
url_agenda: ~
url_website: ~
url_audio: ~
url_code: ~
url_pdf: ~
date_end: '2021-05-25T11:30:00-07:00'
all_day: no
publishDate: '2021-05-22T23:11:09-07:00'
authors: []
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
slides: ''
projects: []
location: ~
address:
  street: ~
  city: ~
  region: ~
  postcode: ~
  country: ~
summary: ~
abstract: ~
speaker: Polo Chau (Georgia Tech)
---
<!--more-->
 AI and ML models are often vulnerable to adversarial attacks, and their predictions can be difficult to understand, evaluate and ultimately act upon. We present recent research highlights: ShapeShifter, the worldâ€™s first targeted adversarial technique that fools state-of-the-art object detector; MalNet, the largest public cybersecurity database with over 1.2M graphs and images; Summit and Bluff, systems that scalably summarize and visualize what features a deep learning model has learned, how those features interact to make predictions; CNN Explainer and GAN Lab (with Google Brain): a suite of accessible tools for students and experts alike to learn about AI models (both went viral).