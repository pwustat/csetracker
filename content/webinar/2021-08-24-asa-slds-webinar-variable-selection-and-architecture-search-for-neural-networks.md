---
title: 'ASA SLDS Webinar: Variable Selection and Architecture Search for Neural Networks'
author: ''
date: '2021-08-24T11:00:00-07:00'
slug: asa-slds-webinar-variable-selection-and-architecture-search-for-neural-networks
categories: []
tags: []
type: webinar
url_register: ~
url_freeregister: https://www.eventbrite.com/e/asa-slds-webinar-tickets-165782683469
url_slides: ~
url_video: no
url_agenda: ~
url_website: ~
url_audio: ~
url_code: ~
url_pdf: ~
date_end: '2021-08-24T12:30:00-07:00'
all_day: no
publishDate: '2021-08-20T09:56:12-07:00'
authors: []
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
slides: ''
projects: []
location: ~
address:
  street: ~
  city: ~
  region: ~
  postcode: ~
  country: ~
summary: ~
abstract: ~
speaker: Jean Feng (UCSF)
---
<!--more-->
Deep learning has accomplished unprecedented performance accuracies in settings with big data and large computational resources. In this talk, we explore whether deep learning can be successful in smaller-scale settings, even those where the number of variables far exceeds the number of observations. We show that adding a sparse group lasso penalty to the training loss induces variable selection and drastically improves prediction accuracy. We then introduce skip-connections, which allow us to perform variable selection and architecture search simultaneously. The resulting training procedure only requires tuning two hyper-parameters, making deep learning practical even in settings with limited data or computational resources.